{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YoUPke2V8hwe"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF5uhTnv6pb_"
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PrFJ5HD8kxV"
   },
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "def collect_data():\n",
    "\n",
    "    # Data from the John Hopkins University Dataset on GitHub\n",
    "    # https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "    # Defining the variables required\n",
    "    filenames = ['time_series_covid19_confirmed_global.csv',\n",
    "                'time_series_covid19_deaths_global.csv',\n",
    "                'time_series_covid19_recovered_global.csv']\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "\n",
    "    # Making the main dataframes required for the analysis\n",
    "    confirmed_global = pd.read_csv(url + filenames[0])\n",
    "    deaths_global = pd.read_csv(url + filenames[1])\n",
    "    recovered_global = pd.read_csv(url + filenames[2])\n",
    "    country_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "\n",
    "    # Simple Data Cleaning - Removing and renaming the Columns\n",
    "\n",
    "    # Removing the Province/State column, as it is pretty much not of any use\n",
    "    confirmed_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    deaths_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    recovered_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    country_cases.drop(columns = ['Last_Update', 'Incident_Rate', 'People_Tested', 'People_Hospitalized', 'UID'], inplace = True)\n",
    "    # Renaming the columns for easier access\n",
    "    confirmed_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    deaths_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    recovered_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "\n",
    "    country_cases.rename(columns = {\n",
    "        \"Country_Region\" : \"country\",\n",
    "        \"Confirmed\": \"confirmed\",\n",
    "        \"Deaths\": \"deaths\",\n",
    "        \"Recovered\" : \"recovered\",\n",
    "        \"Active\" : \"active\",\n",
    "        \"Mortality_Rate\": \"mortality\"\n",
    "    }, inplace = True)\n",
    "\n",
    "    # Removing some duplicate values from the table\n",
    "    confirmed_global = confirmed_global.groupby(['country'], as_index = False).sum()\n",
    "    deaths_global = deaths_global.groupby(['country'], as_index = False).sum()\n",
    "    recovered_global = recovered_global.groupby(['country'], as_index = False).sum()\n",
    "\n",
    "    # This value is being changed as there was an error in the original dataset that had to be modified\n",
    "    confirmed_global.at[178, '5/20/20'] = 251667\n",
    "\n",
    "    return (confirmed_global, deaths_global, recovered_global, country_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dwk4-iLB8_YF"
   },
   "outputs": [],
   "source": [
    "def get_new_cases(country):\n",
    "    time_series = confirmed_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "4t1Ve8Kf9FC8",
    "outputId": "4dd79978-b425-43a0-b30c-ac6a412af7e5"
   },
   "outputs": [],
   "source": [
    "confirmed_global, deaths_global, recovered_global, country_cases = collect_data()\n",
    "confirmed_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIIkg0zh9P1t"
   },
   "outputs": [],
   "source": [
    "country_choice = 'India'\n",
    "dataset = get_new_cases(country_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "XRzsKdah9ZLe",
    "outputId": "1f1c4e80-553c-4487-d679-fe2c8ca88fbb"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmwGhOWj9bB2"
   },
   "outputs": [],
   "source": [
    "# Making the training dataset and test dataset\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * len(dataset))\n",
    "training_set = dataset.iloc[:train_size, 1:2].values\n",
    "test_set = dataset.iloc[train_size:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqKOFJbVJkHS"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJ_pG1fHLtvV"
   },
   "outputs": [],
   "source": [
    "timesteps = 14\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, train_size):\n",
    "  X_train.append(training_set_scaled[i - timesteps: i, 0])\n",
    "  y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euTEDrXoMe4j"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzvmHKnWMyfo"
   },
   "source": [
    "## Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTPrs795MxWk"
   },
   "outputs": [],
   "source": [
    "# Importing the keras libraries and packages required\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cs7nn8_RNN0c"
   },
   "outputs": [],
   "source": [
    "# Initialize the RNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ET_6OwDNTHW"
   },
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and dropout regularization\n",
    "model.add(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOGObtXEOSm1"
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(units = 200, activation = 'relu', return_sequences = True))\n",
    "\n",
    "model.add(LSTM(units = 180, activation = 'relu', return_sequences = True))\n",
    "\n",
    "model.add(LSTM(units = 150, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4b2TT-ipO7ot"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NwX23KdGPsAM",
    "outputId": "e5c4ba8a-ad35-4239-85c8-c2bac71645f0"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 25, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPdMKNkiP8wA"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[:, 1:2]\n",
    "inputs = dataset[train_size - timesteps:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timesteps, len(inputs)):\n",
    "  X_test.append(inputs[i - timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "i99MVHJnltly",
    "outputId": "29c6b19c-438b-4fcc-e3c9-b6fb99842dc3"
   },
   "outputs": [],
   "source": [
    "predicted_cases = model.predict(X_test)\n",
    "predicted_cases = sc.inverse_transform(predicted_cases)\n",
    "predicted_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e-anO4IpUPTB",
    "outputId": "85214248-3d05-460e-d1d5-69f72cb4728d"
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "test_error = mape(test_set, predicted_cases)\n",
    "print(f'Error is {test_error}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'./models/{country_choice}___{round(test_error, 2)}___MAPE')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COVID-19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
