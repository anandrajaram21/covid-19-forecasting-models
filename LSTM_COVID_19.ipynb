{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epPROhFnpLUa"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3pWTiBiozGP"
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdAgodL2o4iw"
   },
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "def collect_data():\n",
    "\n",
    "    # Data from the John Hopkins University Dataset on GitHub\n",
    "    # https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "    # Defining the variables required\n",
    "    filenames = ['time_series_covid19_confirmed_global.csv',\n",
    "                'time_series_covid19_deaths_global.csv',\n",
    "                'time_series_covid19_recovered_global.csv']\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "\n",
    "    # Making the main dataframes required for the analysis\n",
    "    confirmed_global = pd.read_csv(url + filenames[0])\n",
    "    deaths_global = pd.read_csv(url + filenames[1])\n",
    "    recovered_global = pd.read_csv(url + filenames[2])\n",
    "    country_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "\n",
    "    # Simple Data Cleaning - Removing and renaming the Columns\n",
    "\n",
    "    # Removing the Province/State column, as it is pretty much not of any use\n",
    "    confirmed_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    deaths_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    recovered_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    country_cases.drop(columns = ['Last_Update', 'Incident_Rate', 'People_Tested', 'People_Hospitalized', 'UID'], inplace = True)\n",
    "    # Renaming the columns for easier access\n",
    "    confirmed_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    deaths_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    recovered_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "\n",
    "    country_cases.rename(columns = {\n",
    "        \"Country_Region\" : \"country\",\n",
    "        \"Confirmed\": \"confirmed\",\n",
    "        \"Deaths\": \"deaths\",\n",
    "        \"Recovered\" : \"recovered\",\n",
    "        \"Active\" : \"active\",\n",
    "        \"Mortality_Rate\": \"mortality\"\n",
    "    }, inplace = True)\n",
    "\n",
    "    # Removing some duplicate values from the table\n",
    "    confirmed_global = confirmed_global.groupby(['country'], as_index = False).sum()\n",
    "    deaths_global = deaths_global.groupby(['country'], as_index = False).sum()\n",
    "    recovered_global = recovered_global.groupby(['country'], as_index = False).sum()\n",
    "\n",
    "    # This value is being changed as there was an error in the original dataset that had to be modified\n",
    "    confirmed_global.at[178, '5/20/20'] = 251667\n",
    "\n",
    "    return (confirmed_global, deaths_global, recovered_global, country_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "4hm7afSvo846",
    "outputId": "fdb2be03-daea-439d-cbff-6ca0cb9c9c71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>...</th>\n",
       "      <th>9/11/20</th>\n",
       "      <th>9/12/20</th>\n",
       "      <th>9/13/20</th>\n",
       "      <th>9/14/20</th>\n",
       "      <th>9/15/20</th>\n",
       "      <th>9/16/20</th>\n",
       "      <th>9/17/20</th>\n",
       "      <th>9/18/20</th>\n",
       "      <th>9/19/20</th>\n",
       "      <th>9/20/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38606</td>\n",
       "      <td>38641</td>\n",
       "      <td>38716</td>\n",
       "      <td>38772</td>\n",
       "      <td>38815</td>\n",
       "      <td>38855</td>\n",
       "      <td>38872</td>\n",
       "      <td>38883</td>\n",
       "      <td>38919</td>\n",
       "      <td>39044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11021</td>\n",
       "      <td>11185</td>\n",
       "      <td>11353</td>\n",
       "      <td>11520</td>\n",
       "      <td>11672</td>\n",
       "      <td>11816</td>\n",
       "      <td>11948</td>\n",
       "      <td>12073</td>\n",
       "      <td>12226</td>\n",
       "      <td>12385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47752</td>\n",
       "      <td>48007</td>\n",
       "      <td>48254</td>\n",
       "      <td>48496</td>\n",
       "      <td>48734</td>\n",
       "      <td>48966</td>\n",
       "      <td>49194</td>\n",
       "      <td>49413</td>\n",
       "      <td>49623</td>\n",
       "      <td>49826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1438</td>\n",
       "      <td>1438</td>\n",
       "      <td>1483</td>\n",
       "      <td>1483</td>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3279</td>\n",
       "      <td>3335</td>\n",
       "      <td>3388</td>\n",
       "      <td>3439</td>\n",
       "      <td>3569</td>\n",
       "      <td>3675</td>\n",
       "      <td>3789</td>\n",
       "      <td>3848</td>\n",
       "      <td>3901</td>\n",
       "      <td>3991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29256</td>\n",
       "      <td>29906</td>\n",
       "      <td>30574</td>\n",
       "      <td>31362</td>\n",
       "      <td>32250</td>\n",
       "      <td>33006</td>\n",
       "      <td>33843</td>\n",
       "      <td>34401</td>\n",
       "      <td>35003</td>\n",
       "      <td>35686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2013</td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "      <td>2022</td>\n",
       "      <td>2024</td>\n",
       "      <td>2026</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13323</td>\n",
       "      <td>13466</td>\n",
       "      <td>13539</td>\n",
       "      <td>13720</td>\n",
       "      <td>13819</td>\n",
       "      <td>13887</td>\n",
       "      <td>13928</td>\n",
       "      <td>14022</td>\n",
       "      <td>14070</td>\n",
       "      <td>14131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7479</td>\n",
       "      <td>7508</td>\n",
       "      <td>7526</td>\n",
       "      <td>7531</td>\n",
       "      <td>7576</td>\n",
       "      <td>7598</td>\n",
       "      <td>7633</td>\n",
       "      <td>7647</td>\n",
       "      <td>7672</td>\n",
       "      <td>7683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                country  1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  \\\n",
       "0           Afghanistan        0        0        0        0        0        0   \n",
       "1               Albania        0        0        0        0        0        0   \n",
       "2               Algeria        0        0        0        0        0        0   \n",
       "3               Andorra        0        0        0        0        0        0   \n",
       "4                Angola        0        0        0        0        0        0   \n",
       "..                  ...      ...      ...      ...      ...      ...      ...   \n",
       "183  West Bank and Gaza        0        0        0        0        0        0   \n",
       "184      Western Sahara        0        0        0        0        0        0   \n",
       "185               Yemen        0        0        0        0        0        0   \n",
       "186              Zambia        0        0        0        0        0        0   \n",
       "187            Zimbabwe        0        0        0        0        0        0   \n",
       "\n",
       "     1/28/20  1/29/20  1/30/20  ...  9/11/20  9/12/20  9/13/20  9/14/20  \\\n",
       "0          0        0        0  ...    38606    38641    38716    38772   \n",
       "1          0        0        0  ...    11021    11185    11353    11520   \n",
       "2          0        0        0  ...    47752    48007    48254    48496   \n",
       "3          0        0        0  ...     1344     1344     1344     1438   \n",
       "4          0        0        0  ...     3279     3335     3388     3439   \n",
       "..       ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "183        0        0        0  ...    29256    29906    30574    31362   \n",
       "184        0        0        0  ...       10       10       10       10   \n",
       "185        0        0        0  ...     2007     2009     2011     2013   \n",
       "186        0        0        0  ...    13323    13466    13539    13720   \n",
       "187        0        0        0  ...     7479     7508     7526     7531   \n",
       "\n",
       "     9/15/20  9/16/20  9/17/20  9/18/20  9/19/20  9/20/20  \n",
       "0      38815    38855    38872    38883    38919    39044  \n",
       "1      11672    11816    11948    12073    12226    12385  \n",
       "2      48734    48966    49194    49413    49623    49826  \n",
       "3       1438     1483     1483     1564     1564     1564  \n",
       "4       3569     3675     3789     3848     3901     3991  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "183    32250    33006    33843    34401    35003    35686  \n",
       "184       10       10       10       10       10       10  \n",
       "185     2016     2019     2022     2024     2026     2026  \n",
       "186    13819    13887    13928    14022    14070    14131  \n",
       "187     7576     7598     7633     7647     7672     7683  \n",
       "\n",
       "[188 rows x 244 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmed_global, deaths_global, recovered_global, country_cases = collect_data()\n",
    "confirmed_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IHnVmDMpCf2"
   },
   "outputs": [],
   "source": [
    "def get_new_cases(country):\n",
    "    time_series = confirmed_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series_cases = time_series['cases'].diff()\n",
    "    time_series_cases = time_series_cases.replace(np.nan, 0)\n",
    "    time_series = pd.DataFrame(data = {\n",
    "        'date': time_series.date,\n",
    "        'cases': time_series_cases\n",
    "    })\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    time_series.date = [x for x in range(len(time_series))]\n",
    "    return time_series\n",
    "\n",
    "def get_new_deaths(country):\n",
    "    time_series = deaths_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series_cases = time_series['cases'].diff()\n",
    "    time_series_cases = time_series_cases.replace(np.nan, 0)\n",
    "    time_series = pd.DataFrame(data = {\n",
    "        'date': time_series.date,\n",
    "        'cases': time_series_cases\n",
    "    })\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    time_series.date = [x for x in range(len(time_series))]\n",
    "    return time_series\n",
    "\n",
    "def get_new_recoveries(country):\n",
    "    time_series = recovered_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series_cases = time_series['cases'].diff()\n",
    "    time_series_cases = time_series_cases.replace(np.nan, 0)\n",
    "    time_series = pd.DataFrame(data = {\n",
    "        'date': time_series.date,\n",
    "        'cases': time_series_cases\n",
    "    })\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    time_series.date = [x for x in range(len(time_series))]\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "bdUuQZDVpE7H",
    "outputId": "3cdcca11-13c9-4adc-e773-cdca0e1f6602"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>90123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>97894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>96424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>93337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>92605.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date    cases\n",
       "8       8      1.0\n",
       "11     11      1.0\n",
       "12     12      1.0\n",
       "40     40      2.0\n",
       "42     42     23.0\n",
       "..    ...      ...\n",
       "237   237  90123.0\n",
       "238   238  97894.0\n",
       "239   239  96424.0\n",
       "240   240  93337.0\n",
       "241   241  92605.0\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_time_series(country_name, param):\n",
    "    time_series = None\n",
    "    if param == 'confirmed':\n",
    "        time_series = get_new_cases(country_name)\n",
    "    elif param == 'deaths':\n",
    "        time_series = get_new_deaths(country_name)\n",
    "    elif param == 'recoveries':\n",
    "        time_series = get_new_recoveries(country_name)\n",
    "        \n",
    "    # Removing the zero values \n",
    "    is_0 = time_series['cases'] != 0\n",
    "    time_series = time_series[is_0]\n",
    "    \n",
    "    return time_series\n",
    "\n",
    "dataset = create_time_series('India', 'confirmed')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmnPBruUpHoM"
   },
   "outputs": [],
   "source": [
    "# Making the training dataset and test dataset\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * len(dataset))\n",
    "training_set = dataset.iloc[:train_size, 1:2].values\n",
    "test_set = dataset.iloc[train_size:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXu4V5oJpV9i"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4o2rZYMpYWX"
   },
   "outputs": [],
   "source": [
    "timesteps = 14\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, train_size):\n",
    "  X_train.append(training_set_scaled[i - timesteps: i, 0])\n",
    "  y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GK_ksCTnpbGL"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[:, 1:2]\n",
    "inputs = dataset[train_size - timesteps:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timesteps, len(inputs)):\n",
    "  X_test.append(inputs[i - timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXZB4iGdpk6G"
   },
   "source": [
    "## Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR7La-eIpn2x"
   },
   "outputs": [],
   "source": [
    "# Importing libraries and packages required\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "\n",
    "# Importing sklearn parameter grid for Hyperparameter tuning\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4ot54shsFnh"
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFwpsaT1prSx"
   },
   "outputs": [],
   "source": [
    "# Setting the random seed for better model reproducibility\n",
    "tf.random.set_seed(365)\n",
    "\n",
    "# The main model building function\n",
    "def build_model(units, activation, batch_size, n_layers, bidirectional, epochs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1))))\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            model.add(Bidirectional(LSTM(units=units, activation=activation, return_sequences=True)))\n",
    "        \n",
    "        model.add(Bidirectional(LSTM(units=units, activation=activation)))\n",
    "        model.add(Dense(units = 1))\n",
    "        \n",
    "    else:\n",
    "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            model.add(LSTM(units=units, activation=activation, return_sequences=True))\n",
    "        \n",
    "        model.add(LSTM(units=units, activation=activation))\n",
    "        model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    predicted_cases = model.predict(X_test)\n",
    "    predicted_cases = sc.inverse_transform(predicted_cases)\n",
    "    \n",
    "    error = mape(test_set, predicted_cases)\n",
    "    \n",
    "    return model, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jZZUpRCp1sm"
   },
   "outputs": [],
   "source": [
    "def hp_tuning():\n",
    "    params = {\n",
    "        'units': [150, 200, 250, 300],\n",
    "        'activation': ['relu', 'swish'],\n",
    "        'batch_size': [16, 32],\n",
    "        'n_layers': [2, 3, 4],\n",
    "        'bidirectional': [True]\n",
    "    }\n",
    "    \n",
    "    params = ParameterGrid(params)\n",
    "\n",
    "    model = None\n",
    "    err = 1000\n",
    "    arch = None\n",
    "\n",
    "    for i in params:\n",
    "        print(i)\n",
    "        model_in, err_in = build_model(i['units'], i['activation'], i['batch_size'], i['n_layers'], i['bidirectional'], 30) \n",
    "        results.append((model_in, err_in))\n",
    "        print(f'Model has an error of {err_in}%')\n",
    "        if err_in < err:\n",
    "            model = model_in\n",
    "            err = err_in\n",
    "            arch = i\n",
    "\n",
    "    return model, err, arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21IbaoL5rBZv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0669\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0168\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0109\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0053\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0045\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0013\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0014\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0011\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 8.0194e-04\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 9.6318e-04\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 8.1317e-04\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 9.8683e-04\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 9.8291e-04\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0014\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0014\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 8.6991e-04\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0013\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0018\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 8.3445e-04\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0012\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 9.2948e-04\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 9.2161e-04\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 8.1124e-04\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0013\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0014\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0011\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 8.1764e-04\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 7.3609e-04\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 8.0194e-04\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 8.4620e-04\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 7.7351e-04\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0014\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0012\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0013\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 9.3588e-04\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0017\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0023\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0011\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 9.6642e-04\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 9.2723e-04\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0016\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0013\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0010\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 7.3825e-04\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 6.7282e-04\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 7.3720e-04\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0010\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 6.9118e-04\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 7.4072e-04\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 9.0742e-04\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0013\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0013\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 9.8400e-04\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0013\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 6.8926e-04\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 7.3800e-04\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 8.4152e-04\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0011\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0015\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 7.4644e-04\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 7.8718e-04\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 9.2700e-04\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 7.6766e-04\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0011\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 8.5499e-04\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 7.9854e-04\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 8.5270e-04\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 7.6089e-04\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 7.3467e-04\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0012\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0017\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0011\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.0013\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 8.1396e-04\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 8.4602e-04\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 9.6315e-04\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.0014\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 9.5399e-04\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 9.0466e-04\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 7.0791e-04\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0011\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 8.1323e-04\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.0012\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 7.7120e-04\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 8.5025e-04\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 8.8382e-04\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 8.4931e-04\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0013\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 9.2248e-04\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 6.9308e-04\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 8.2890e-04\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 8.6757e-04\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0016\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 8.8487e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.491445347918924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, error = build_model(150, 'relu', 16, 3, True, 100)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM-COVID-19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
