{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epPROhFnpLUa"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3pWTiBiozGP"
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdAgodL2o4iw"
   },
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "def collect_data():\n",
    "\n",
    "    # Data from the John Hopkins University Dataset on GitHub\n",
    "    # https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "    # Defining the variables required\n",
    "    filenames = ['time_series_covid19_confirmed_global.csv',\n",
    "                'time_series_covid19_deaths_global.csv',\n",
    "                'time_series_covid19_recovered_global.csv']\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "\n",
    "    # Making the main dataframes required for the analysis\n",
    "    confirmed_global = pd.read_csv(url + filenames[0])\n",
    "    deaths_global = pd.read_csv(url + filenames[1])\n",
    "    recovered_global = pd.read_csv(url + filenames[2])\n",
    "    country_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "\n",
    "    # Simple Data Cleaning - Removing and renaming the Columns\n",
    "\n",
    "    # Removing the Province/State column, as it is pretty much not of any use\n",
    "    confirmed_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    deaths_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    recovered_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "    country_cases.drop(columns = ['Last_Update', 'Incident_Rate', 'People_Tested', 'People_Hospitalized', 'UID'], inplace = True)\n",
    "    # Renaming the columns for easier access\n",
    "    confirmed_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    deaths_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "    recovered_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "\n",
    "    country_cases.rename(columns = {\n",
    "        \"Country_Region\" : \"country\",\n",
    "        \"Confirmed\": \"confirmed\",\n",
    "        \"Deaths\": \"deaths\",\n",
    "        \"Recovered\" : \"recovered\",\n",
    "        \"Active\" : \"active\",\n",
    "        \"Mortality_Rate\": \"mortality\"\n",
    "    }, inplace = True)\n",
    "\n",
    "    # Removing some duplicate values from the table\n",
    "    confirmed_global = confirmed_global.groupby(['country'], as_index = False).sum()\n",
    "    deaths_global = deaths_global.groupby(['country'], as_index = False).sum()\n",
    "    recovered_global = recovered_global.groupby(['country'], as_index = False).sum()\n",
    "\n",
    "    # This value is being changed as there was an error in the original dataset that had to be modified\n",
    "    confirmed_global.at[178, '5/20/20'] = 251667\n",
    "\n",
    "    return (confirmed_global, deaths_global, recovered_global, country_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "4hm7afSvo846",
    "outputId": "fdb2be03-daea-439d-cbff-6ca0cb9c9c71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>...</th>\n",
       "      <th>9/10/20</th>\n",
       "      <th>9/11/20</th>\n",
       "      <th>9/12/20</th>\n",
       "      <th>9/13/20</th>\n",
       "      <th>9/14/20</th>\n",
       "      <th>9/15/20</th>\n",
       "      <th>9/16/20</th>\n",
       "      <th>9/17/20</th>\n",
       "      <th>9/18/20</th>\n",
       "      <th>9/19/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38572</td>\n",
       "      <td>38606</td>\n",
       "      <td>38641</td>\n",
       "      <td>38716</td>\n",
       "      <td>38772</td>\n",
       "      <td>38815</td>\n",
       "      <td>38855</td>\n",
       "      <td>38872</td>\n",
       "      <td>38883</td>\n",
       "      <td>38919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10860</td>\n",
       "      <td>11021</td>\n",
       "      <td>11185</td>\n",
       "      <td>11353</td>\n",
       "      <td>11520</td>\n",
       "      <td>11672</td>\n",
       "      <td>11816</td>\n",
       "      <td>11948</td>\n",
       "      <td>12073</td>\n",
       "      <td>12226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47488</td>\n",
       "      <td>47752</td>\n",
       "      <td>48007</td>\n",
       "      <td>48254</td>\n",
       "      <td>48496</td>\n",
       "      <td>48734</td>\n",
       "      <td>48966</td>\n",
       "      <td>49194</td>\n",
       "      <td>49413</td>\n",
       "      <td>49623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1301</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>1438</td>\n",
       "      <td>1438</td>\n",
       "      <td>1483</td>\n",
       "      <td>1483</td>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3217</td>\n",
       "      <td>3279</td>\n",
       "      <td>3335</td>\n",
       "      <td>3388</td>\n",
       "      <td>3439</td>\n",
       "      <td>3569</td>\n",
       "      <td>3675</td>\n",
       "      <td>3789</td>\n",
       "      <td>3848</td>\n",
       "      <td>3901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28664</td>\n",
       "      <td>29256</td>\n",
       "      <td>29906</td>\n",
       "      <td>30574</td>\n",
       "      <td>31362</td>\n",
       "      <td>32250</td>\n",
       "      <td>33006</td>\n",
       "      <td>33843</td>\n",
       "      <td>34401</td>\n",
       "      <td>35003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003</td>\n",
       "      <td>2007</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2013</td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "      <td>2022</td>\n",
       "      <td>2024</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13214</td>\n",
       "      <td>13323</td>\n",
       "      <td>13466</td>\n",
       "      <td>13539</td>\n",
       "      <td>13720</td>\n",
       "      <td>13819</td>\n",
       "      <td>13887</td>\n",
       "      <td>13928</td>\n",
       "      <td>14022</td>\n",
       "      <td>14070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7453</td>\n",
       "      <td>7479</td>\n",
       "      <td>7508</td>\n",
       "      <td>7526</td>\n",
       "      <td>7531</td>\n",
       "      <td>7576</td>\n",
       "      <td>7598</td>\n",
       "      <td>7633</td>\n",
       "      <td>7647</td>\n",
       "      <td>7672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                country  1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  \\\n",
       "0           Afghanistan        0        0        0        0        0        0   \n",
       "1               Albania        0        0        0        0        0        0   \n",
       "2               Algeria        0        0        0        0        0        0   \n",
       "3               Andorra        0        0        0        0        0        0   \n",
       "4                Angola        0        0        0        0        0        0   \n",
       "..                  ...      ...      ...      ...      ...      ...      ...   \n",
       "183  West Bank and Gaza        0        0        0        0        0        0   \n",
       "184      Western Sahara        0        0        0        0        0        0   \n",
       "185               Yemen        0        0        0        0        0        0   \n",
       "186              Zambia        0        0        0        0        0        0   \n",
       "187            Zimbabwe        0        0        0        0        0        0   \n",
       "\n",
       "     1/28/20  1/29/20  1/30/20  ...  9/10/20  9/11/20  9/12/20  9/13/20  \\\n",
       "0          0        0        0  ...    38572    38606    38641    38716   \n",
       "1          0        0        0  ...    10860    11021    11185    11353   \n",
       "2          0        0        0  ...    47488    47752    48007    48254   \n",
       "3          0        0        0  ...     1301     1344     1344     1344   \n",
       "4          0        0        0  ...     3217     3279     3335     3388   \n",
       "..       ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "183        0        0        0  ...    28664    29256    29906    30574   \n",
       "184        0        0        0  ...       10       10       10       10   \n",
       "185        0        0        0  ...     2003     2007     2009     2011   \n",
       "186        0        0        0  ...    13214    13323    13466    13539   \n",
       "187        0        0        0  ...     7453     7479     7508     7526   \n",
       "\n",
       "     9/14/20  9/15/20  9/16/20  9/17/20  9/18/20  9/19/20  \n",
       "0      38772    38815    38855    38872    38883    38919  \n",
       "1      11520    11672    11816    11948    12073    12226  \n",
       "2      48496    48734    48966    49194    49413    49623  \n",
       "3       1438     1438     1483     1483     1564     1564  \n",
       "4       3439     3569     3675     3789     3848     3901  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "183    31362    32250    33006    33843    34401    35003  \n",
       "184       10       10       10       10       10       10  \n",
       "185     2013     2016     2019     2022     2024     2026  \n",
       "186    13720    13819    13887    13928    14022    14070  \n",
       "187     7531     7576     7598     7633     7647     7672  \n",
       "\n",
       "[188 rows x 243 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmed_global, deaths_global, recovered_global, country_cases = collect_data()\n",
    "confirmed_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IHnVmDMpCf2"
   },
   "outputs": [],
   "source": [
    "def get_new_cases(country):\n",
    "    time_series = confirmed_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    return time_series\n",
    "\n",
    "def get_new_deaths(country):\n",
    "    time_series = deaths_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    return time_series\n",
    "\n",
    "def get_new_recoveries(country):\n",
    "    time_series = recovered_global.melt(id_vars = ['country'], var_name = 'date', value_name = 'cases')\n",
    "    time_series = time_series[time_series['country'] == country]\n",
    "    time_series = time_series.drop(['country'], axis = 1)\n",
    "    time_series.index = [x for x in range(len(time_series))]\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "bdUuQZDVpE7H",
    "outputId": "3cdcca11-13c9-4adc-e773-cdca0e1f6602"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>9/15/20</td>\n",
       "      <td>5020359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>9/16/20</td>\n",
       "      <td>5118253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>9/17/20</td>\n",
       "      <td>5214677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>9/18/20</td>\n",
       "      <td>5214677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>9/19/20</td>\n",
       "      <td>5308014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    cases\n",
       "0    1/22/20        0\n",
       "1    1/23/20        0\n",
       "2    1/24/20        0\n",
       "3    1/25/20        0\n",
       "4    1/26/20        0\n",
       "..       ...      ...\n",
       "237  9/15/20  5020359\n",
       "238  9/16/20  5118253\n",
       "239  9/17/20  5214677\n",
       "240  9/18/20  5214677\n",
       "241  9/19/20  5308014\n",
       "\n",
       "[242 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_time_series(country_name, param):\n",
    "    time_series = None\n",
    "    if param == 'confirmed':\n",
    "        time_series = get_new_cases(country_name)\n",
    "    elif param == 'deaths':\n",
    "        time_series = get_new_deaths(country_name)\n",
    "    elif param == 'recoveries':\n",
    "        time_series = get_new_recoveries(country_name)\n",
    "    return time_series\n",
    "\n",
    "dataset = create_time_series('India', 'confirmed')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmnPBruUpHoM"
   },
   "outputs": [],
   "source": [
    "# Making the training dataset and test dataset\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * len(dataset))\n",
    "training_set = dataset.iloc[:train_size, 1:2].values\n",
    "test_set = dataset.iloc[train_size:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXu4V5oJpV9i"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4o2rZYMpYWX"
   },
   "outputs": [],
   "source": [
    "timesteps = 14\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, train_size):\n",
    "  X_train.append(training_set_scaled[i - timesteps: i, 0])\n",
    "  y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GK_ksCTnpbGL"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[:, 1:2]\n",
    "inputs = dataset[train_size - timesteps:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timesteps, len(inputs)):\n",
    "  X_test.append(inputs[i - timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXZB4iGdpk6G"
   },
   "source": [
    "## Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR7La-eIpn2x"
   },
   "outputs": [],
   "source": [
    "# Importing libraries and packages required\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "\n",
    "# Importing sklearn parameter grid for Hyperparameter tuning\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4ot54shsFnh"
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFwpsaT1prSx"
   },
   "outputs": [],
   "source": [
    "# Setting the random seed for better model reproducibility\n",
    "tf.random.set_seed(365)\n",
    "\n",
    "# The main model building function\n",
    "def build_model(units, activation, batch_size, n_layers, bidirectional, epochs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1))))\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            model.add(Bidirectional(LSTM(units=units, activation=activation, return_sequences=True)))\n",
    "        \n",
    "        model.add(Bidirectional(LSTM(units=units, activation=activation)))\n",
    "        model.add(Dense(units = 1))\n",
    "        \n",
    "    else:\n",
    "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            model.add(LSTM(units=units, activation=activation, return_sequences=True))\n",
    "        \n",
    "        model.add(LSTM(units=units, activation=activation))\n",
    "        model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    predicted_cases = model.predict(X_test)\n",
    "    predicted_cases = sc.inverse_transform(predicted_cases)\n",
    "    \n",
    "    error = mape(test_set, predicted_cases)\n",
    "    \n",
    "    return model, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jZZUpRCp1sm"
   },
   "outputs": [],
   "source": [
    "def hp_tuning():\n",
    "    params = {\n",
    "        'units': [150, 200, 250, 300],\n",
    "        'activation': ['relu', 'swish'],\n",
    "        'batch_size': [16, 32],\n",
    "        'n_layers': [2, 3, 4],\n",
    "        'bidirectional': [True]\n",
    "    }\n",
    "    \n",
    "    params = ParameterGrid(params)\n",
    "\n",
    "    model = None\n",
    "    err = 1000\n",
    "    arch = None\n",
    "\n",
    "    for i in params:\n",
    "        print(i)\n",
    "        model_in, err_in = build_model(i['units'], i['activation'], i['batch_size'], i['n_layers'], i['bidirectional'], 30) \n",
    "        results.append((model_in, err_in))\n",
    "        print(f'Model has an error of {err_in}%')\n",
    "        if err_in < err:\n",
    "            model = model_in\n",
    "            err = err_in\n",
    "            arch = i\n",
    "\n",
    "    return model, err, arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21IbaoL5rBZv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 0.0282\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.0034\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 4.4973e-04\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 2.1563e-04\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 1.2215e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 6.1111e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 8.5837e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.0023\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 0.0062\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 0.0031\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.0019\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.0011\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 4.8930e-04\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.0011\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 3s 257ms/step - loss: 0.0010\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 2.8996e-04\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 8.5130e-05\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 3.9167e-05\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 2.0907e-05\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 1.2769e-05\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 9.4531e-06\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1.1697e-05\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 6.0336e-06\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 3.1239e-06\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 3.2775e-06\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 3.4051e-06\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 4.9851e-06\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.1321e-06\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.4914e-05\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 6.6005e-06\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 8.3696e-06\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 7.7065e-06\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 8.7678e-06\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 2.6082e-06\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 2.7382e-06\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.1667e-06\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 6.6743e-06\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 2.3131e-06\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 2.6417e-06\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 5.0598e-06\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 3.2833e-06\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 6.4996e-06\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 6.7667e-06\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 6.0024e-06\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 200ms/step - loss: 5.4629e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 1.0047e-04\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 200ms/step - loss: 1.1675e-04\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 3s 212ms/step - loss: 3.3611e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 3s 260ms/step - loss: 1.7849e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 9.2022e-06\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 1.6875e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 6.6340e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 5.6063e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 2.2654e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 177ms/step - loss: 2.6952e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 5.3491e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 6.5740e-05\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 4.2289e-04\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 2.4468e-04\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 7.7112e-04\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 7.0213e-04\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 6.5234e-04\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 2s 199ms/step - loss: 1.2538e-04\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.9071e-04\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 2.6105e-04\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 8.6486e-05\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 2.0974e-05\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.4994e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 8.0445e-06\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.0053e-05\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 2s 140ms/step - loss: 1.3002e-05\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 3s 210ms/step - loss: 3.3102e-05\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 4.6104e-05\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 1.4207e-05\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 6.6883e-06\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 5.3050e-06\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 1.0144e-05\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 2s 183ms/step - loss: 1.5377e-05\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 3.4431e-05\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 1.9835e-05\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 3s 221ms/step - loss: 5.2677e-05\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 203ms/step - loss: 7.0638e-05\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 6.7358e-05\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 2.6438e-05\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 1.1756e-05\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 1.2329e-05\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1.8507e-05\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.3526e-05\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 179ms/step - loss: 1.4898e-05\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 1.6702e-05\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 1.3740e-05\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 6.9600e-06\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 8.9674e-06\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 9.6112e-06\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 3.3000e-05\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 175ms/step - loss: 1.8495e-05\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 6.1256e-06\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 3.7602e-06\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 3.9229e-05\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 1.5852e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.345107942931135"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, error = build_model(150, 'relu', 16, 3, True, 100)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM-COVID-19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
